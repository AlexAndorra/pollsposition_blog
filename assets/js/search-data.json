{
  
    
        "post0": {
            "title": "How popular is the President?",
            "content": "This notebook tests how a Gaussian Process model can perform in predicting French presidents&#39; popularity since the term limits switched to 5 years. . PARTIES = { &quot;chirac2&quot;: &quot;right&quot;, &quot;sarkozy&quot;: &quot;right&quot;, &quot;hollande&quot;: &quot;left&quot;, &quot;macron&quot;: &quot;center&quot;, } def standardize(series): &quot;&quot;&quot;Standardize a pandas series&quot;&quot;&quot; return (series - series.mean()) / series.std() . . all_presidents = pd.read_excel( &quot;../data/raw_popularity_presidents.xlsx&quot;, index_col=0, parse_dates=True ) . . d = all_presidents.loc[all_presidents.index &gt;= pd.to_datetime(&quot;2002-05-05&quot;)] # convert to proportions d[[&quot;approve_pr&quot;, &quot;disapprove_pr&quot;]] = d[[&quot;approve_pr&quot;, &quot;disapprove_pr&quot;]].copy() / 100 d = d.rename(columns={&quot;approve_pr&quot;: &quot;p_approve&quot;, &quot;disapprove_pr&quot;: &quot;p_disapprove&quot;}) # raw monthly average to get fixed time intervals # TODO: replace by poll aggregation d = d.groupby(&quot;president&quot;).resample(&quot;M&quot;).mean().reset_index(level=0).sort_index() d[&quot;party&quot;] = d.president.replace(PARTIES) . /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy self[k1] = value[k2] . ELECTION_FLAGS = ( (d.index.year == 2002) &amp; (d.index.month == 5) | (d.index.year == 2007) &amp; (d.index.month == 5) | (d.index.year == 2012) &amp; (d.index.month == 5) | (d.index.year == 2017) &amp; (d.index.month == 5) ) d[&quot;election_flag&quot;] = 0 d.loc[ELECTION_FLAGS, &quot;election_flag&quot;] = 1 # convert to nbr of successes d[&quot;N_approve&quot;] = d.samplesize * d[&quot;p_approve&quot;] d[&quot;N_disapprove&quot;] = d.samplesize * d[&quot;p_disapprove&quot;] d[[&quot;N_approve&quot;, &quot;N_disapprove&quot;]] = d[[&quot;N_approve&quot;, &quot;N_disapprove&quot;]].round().astype(int) # compute total trials d[&quot;N_total&quot;] = d.N_approve + d.N_disapprove d . president samplesize p_approve p_disapprove party election_flag N_approve N_disapprove N_total . 2002-05-31 chirac2 | 964.250000 | 0.502500 | 0.442500 | right | 1 | 485 | 427 | 912 | . 2002-06-30 chirac2 | 970.000000 | 0.505000 | 0.425000 | right | 0 | 490 | 412 | 902 | . 2002-07-31 chirac2 | 947.333333 | 0.533333 | 0.406667 | right | 0 | 505 | 385 | 890 | . 2002-08-31 chirac2 | 1028.000000 | 0.520000 | 0.416667 | right | 0 | 535 | 428 | 963 | . 2002-09-30 chirac2 | 1017.500000 | 0.525000 | 0.420000 | right | 0 | 534 | 427 | 961 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-08-31 macron | 1006.000000 | 0.376667 | 0.593333 | center | 0 | 379 | 597 | 976 | . 2020-09-30 macron | 1000.500000 | 0.320000 | 0.625000 | center | 0 | 320 | 625 | 945 | . 2020-10-31 macron | 1000.000000 | 0.373333 | 0.573333 | center | 0 | 373 | 573 | 946 | . 2020-11-30 macron | 1188.000000 | 0.384000 | 0.586000 | center | 0 | 456 | 696 | 1152 | . 2020-12-31 macron | 1000.000000 | 0.320000 | 0.640000 | center | 0 | 320 | 640 | 960 | . 224 rows × 9 columns . def dates_to_idx(timelist): &quot;&quot;&quot;Convert datetimes to numbers in reference to a given date. Useful for posterior predictions.&quot;&quot;&quot; reference_time = timelist[0] t = (timelist - reference_time) / np.timedelta64(1, &quot;M&quot;) return np.asarray(t) . time = dates_to_idx(d.index) time[:10] . array([0. , 0.98564652, 2.00414793, 3.02264934, 4.00829586, 5.02679726, 6.01244379, 7.03094519, 8.0494466 , 8.96938335]) . This whole section about prior is outdated and needs to be revised . Priors are very important to fit GPs properly, so let&#39;s spend some time thinking about our priors for a more refined model of the popularity of the president. We start by the priors for the lengthscale and period parameters: . ls_trend: The lengthscale of the long term trend. It has a wide prior with most of the mass between 1 to 3 years. | ls_med: This is the lengthscale for the short to medium long variations. This prior has most of its mass below 2 years. | scale_mixture_rate of the Rational Quadratic kernel: It is equivalent to using a combination of Exponential Quadratic kernels with different length scales. As the scale mixture rate approaches infinity, the kernel becomes exactly equivalent to the Exponential Quadratic Kernel. We center the prior for this parameter around 3, since we’re expecting that there is some more variation than could be explained by an exponentiated quadratic kernel. | period of the semi-periodic component: We don&#39;t have a strong prior on this, so we&#39;ll center the period at one year, with the possibility for short-term seasonality as well as longer seasonality. | ls_period: The smoothness of the semi-periodic component. It controls how “sinusoidal” the periodicity is. The plot of the data shows that seasonality is quite far from a sine wave, so we use a Gamma whose mode is at 2, and a relatively large variance. | ls_period_decay: The periodic decay. The smaller this parameter, the faster the periodicity goes away. I suspect the seasonality of popularity goes away quite quickly, so let&#39;s put most of the prior mass between 6 months and 2 years. | . If you&#39;re a bit lost, that&#39;s quite normal: parameters for GPs are not easily interpretable so it takes some time to develop intuition about them -- all the more so because the Gamma distribution is very flexible, so it can take a lot of different shapes. Here are good educational ressources to think about priors in the context of GPs: . PyMC3&#39;s CO2 at Mauna Loa example notebook. | PyMC3&#39;s notebook for mean and covariance functions. | PyMC4&#39;s notebook for mean and covariance functions. | Michael Betancourt&#39;s &quot;Probabilistic Building Blocks&quot; case-study. | . x = np.linspace(0, 120, 500) priors = [ (r&quot;$ alpha$=5, $ beta$=2&quot;, pm.Gamma.dist(alpha=5, beta=2)), (r&quot;$ alpha$=2, $ beta$=0.5&quot;, pm.Gamma.dist(alpha=2, beta=0.5)), (r&quot;$ alpha$=9, $ beta$=1&quot;, pm.Gamma.dist(alpha=9, beta=1)), (r&quot;$ alpha$=20, $ beta$=1&quot;, pm.Gamma.dist(alpha=20, beta=1)), ] fig = plt.figure(figsize=(12, 5)) for i, prior in enumerate(priors): plt.plot(x, np.exp(prior[1].logp(x).eval()), label=prior[0]) plt.xlim((-1, 40)) plt.xlabel(&quot;Months&quot;) plt.ylabel(&quot;Density&quot;) plt.title(&quot;Lengthscale priors&quot;) plt.legend(); . Now we have to think about priors for our scale parameters: amplitude_trend (the scale of the long term trend), amplitude_med (the scale of the short to medium term component), and amplitude_per (the scale of the semi-periodic component). We don&#39;t have a lot of prior information about these parameters, so let&#39;s choose a weakly informative prior: . x = np.linspace(0, 12, 500) priors = [ (&quot;Exponential&quot;, pm.Exponential.dist(1)), (&quot;HalfNormal&quot;, pm.HalfNormal.dist(1)), ] fig = plt.figure(figsize=(12, 5)) for i, prior in enumerate(priors): plt.plot(x, np.exp(prior[1].logp(x).eval()), label=prior[0]) plt.xlabel(&quot;Months&quot;) plt.ylabel(&quot;Density&quot;) plt.title(&quot;Amplitude priors&quot;) plt.legend(); . And now we can use these priors to simulate samples from the whole GP prior and see if our choices make sense: . amplitude_trend = pm.HalfNormal.dist(1.0).random(1) ls_trend = pm.Gamma.dist(alpha=5, beta=2).random(1) cov_trend = amplitude_trend ** 2 * pm.gp.cov.Matern52(1, ls_trend) prior_timepoints = np.linspace(0, 60, 200)[:, None] K = cov_trend(prior_timepoints).eval() gp_prior_samples = pm.MvNormal.dist(mu=np.zeros(K.shape[0]), cov=K).random(size=20_000) . _, (left, mid, right) = plt.subplots( 1, 3, figsize=(16, 5), constrained_layout=True, sharex=True, sharey=True ) for ax, samples in zip((left, mid, right), (5, 10, 100)): ax.plot( prior_timepoints, gp_prior_samples[:samples].T, color=&quot;darkblue&quot;, alpha=0.3, ) ax.set_title(&quot;Samples from the GP prior&quot;) ax.set_xlabel(&quot;Time in months&quot;) ax.set_ylabel(&quot;Popularity evolution&quot;); . _, ax = plt.subplots(1, 1, figsize=(14, 5)) ax.plot( prior_timepoints.flatten(), np.median(gp_prior_samples, axis=0), color=&quot;darkblue&quot; ) az.plot_hdi( prior_timepoints.flatten(), gp_prior_samples, hdi_prob=0.2, ax=ax, color=&quot;darkblue&quot;, fill_kwargs={&quot;alpha&quot;: 0.4}, ) az.plot_hdi( prior_timepoints.flatten(), gp_prior_samples, hdi_prob=0.4, ax=ax, color=&quot;darkblue&quot;, fill_kwargs={&quot;alpha&quot;: 0.3}, ) az.plot_hdi( prior_timepoints.flatten(), gp_prior_samples, hdi_prob=0.6, ax=ax, color=&quot;darkblue&quot;, fill_kwargs={&quot;alpha&quot;: 0.2}, ) az.plot_hdi( prior_timepoints.flatten(), gp_prior_samples, hdi_prob=0.8, ax=ax, color=&quot;darkblue&quot;, fill_kwargs={&quot;alpha&quot;: 0.1}, ) ax.set_title(&quot;Prior marginal quantiles from the GP&quot;) ax.set_xlabel(&quot;Time in months&quot;) ax.set_ylabel(&quot;Popularity evolution&quot;); . /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( . Finally, let&#39;s pick a prior for our baseline parameter, i.e the intercept of our Gaussian Process regression. In other words, this will be the mean function of our GP -- the value it reverts to when data start lacking. There we have quite a lot of information: 50% popularity is historically quite high for a French president (just take a look at the whole dataset we loaded at the beginning of the NB), so keeping the mean at zero is sub-optimal -- remember that baseline lives on the logit scale, so a prior centered at 0 means a prior centered at $logistic(0) = 0.5$ on the outcome space. . We can do better: based on our domain knowledge, we expect most president to have a baseline popularity between 20% and 50% -- in other words, French people rarely love their presidents but often really dislike them. $Normal(-0.7, 0.5)$ looks reasonable in that regard: it expects 95% of the probability mass to be between -1.7 and 0.3, i.e $logistic(-1.7) = 15 %$ and $logistic(0.3) = 57 %$, with a mean approval of $logistic(-0.7) = 33 %$: . baseline_prior_samples = pm.Normal.dist(-0.7, 0.5).random(size=20_000) ax = az.plot_kde( logistic(baseline_prior_samples), label=&quot;baseline ~ $Normal(-0.7, 0.5)$&quot;, ) ax.set_xlim((0, 1)) ax.set_xlabel(&quot;Baseline presidential popularity&quot;) ax.set_ylabel(&quot;Density&quot;) ax.set_title(&quot;Baseline prior&quot;); . honeymoon_prior_samples = pm.Normal.dist(-0.5, 0.3).random(size=20_000) ax = az.plot_kde( logistic(honeymoon_prior_samples), label=&quot;honeymoon_effect ~ $Normal(-0.5, 0.3)$&quot;, ) ax.set_xlim((0, 1)) ax.set_xlabel(&quot;Bonus in popularity due to honeymoon effect&quot;) ax.set_ylabel(&quot;Density&quot;) ax.set_title(&quot;Honeymoon effect prior&quot;) ax.legend(fontsize=12); . unemp_effect_prior_samples = pm.Normal.dist(0.0, 0.2).random(size=20_000) fake_unemp = np.linspace(-3, 3, 200)[None, :] prior_approval = logistic( baseline_prior_samples[:, None] + gp_prior_samples + unemp_effect_prior_samples[:, None] * fake_unemp ) . /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/arviz/stats/stats.py:484: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions warnings.warn( . The unemployment data can be found here. . quarter president samplesize p_approve p_disapprove party election_flag N_approve N_disapprove N_total unemployment . month . 2002-05-31 2002Q2 | chirac2 | 964.250000 | 0.502500 | 0.442500 | right | 1 | 485 | 427 | 912 | 7.5 | . 2002-06-30 2002Q2 | chirac2 | 970.000000 | 0.505000 | 0.425000 | right | 0 | 490 | 412 | 902 | 7.5 | . 2002-07-31 2002Q3 | chirac2 | 947.333333 | 0.533333 | 0.406667 | right | 0 | 505 | 385 | 890 | 7.5 | . 2002-08-31 2002Q3 | chirac2 | 1028.000000 | 0.520000 | 0.416667 | right | 0 | 535 | 428 | 963 | 7.5 | . 2002-09-30 2002Q3 | chirac2 | 1017.500000 | 0.525000 | 0.420000 | right | 0 | 534 | 427 | 961 | 7.5 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 2020-08-31 2020Q3 | macron | 1006.000000 | 0.376667 | 0.593333 | center | 0 | 379 | 597 | 976 | 8.8 | . 2020-09-30 2020Q3 | macron | 1000.500000 | 0.320000 | 0.625000 | center | 0 | 320 | 625 | 945 | 8.8 | . 2020-10-31 2020Q4 | macron | 1000.000000 | 0.373333 | 0.573333 | center | 0 | 373 | 573 | 946 | 8.8 | . 2020-11-30 2020Q4 | macron | 1188.000000 | 0.384000 | 0.586000 | center | 0 | 456 | 696 | 1152 | 8.8 | . 2020-12-31 2020Q4 | macron | 1000.000000 | 0.320000 | 0.640000 | center | 0 | 320 | 640 | 960 | 8.8 | . 224 rows × 11 columns . Explain the forward-fill for unemployment and the difficulties with these data (uncertainty coded in model) | Explain the over-dispersion likelihood (polling error) | . Also, the model will care about the order of magnitude of the unemployment, not the intrisic values, so we take the log of the unemployment. Finally, we need to standardize the data (mean 0 and standard deviation 1) so that our sampler has a better time sampling. Let&#39;s set this up: . x_plot = np.linspace(0, 1, 100) pbar = 0.5 theta = 10.0 plt.plot( x_plot, np.exp(pm.Beta.dist(pbar * theta, (1 - pbar) * theta).logp(x_plot).eval()), label=f&quot;Beta({pbar * theta}, {(1 - pbar) * theta})&quot;, ) plt.xlabel(&quot;Probablity&quot;) plt.ylabel(&quot;Density&quot;) plt.legend(); . COORDS = {&quot;timesteps&quot;: d.index} with pm.Model(coords=COORDS) as econ_latent_gp: # intercept on logit scale baseline = pm.Normal(&quot;baseline&quot;, -0.7, 0.5) # honeymoon slope honeymoon = pm.Normal(&quot;honeymoon&quot;, -0.5, 0.3) # log unemployment slope log_unemp_effect = pm.Normal(&quot;log_unemp_effect&quot;, 0.0, 0.2) # long term trend amplitude_trend = pm.HalfNormal(&quot;amplitude_trend&quot;, 1.0) # ls_trend = pm.InverseGamma(&quot;ls_trend&quot;, alpha=6, beta=14) ls_trend = pm.Gamma(&quot;ls_trend&quot;, alpha=5, beta=2) cov_trend = amplitude_trend ** 2 * pm.gp.cov.Matern52(1, ls_trend) # instantiate gp gp = pm.gp.Latent(cov_func=cov_trend) # evaluate GP at time points f_time = gp.prior(&quot;f_time&quot;, X=time[:, None]) # data election_flag = pm.Data(&quot;election_flag&quot;, d.election_flag.values, dims=&quot;timesteps&quot;) stdz_log_unemployment = pm.Data( &quot;stdz_log_unemployment&quot;, standardize(np.log(d.unemployment)).values, dims=&quot;timesteps&quot;, ) # unemployment data is uncertain # sd = 0.1 says uncertainty on point expected btw 20% of data std 95% of time u_diff = pm.Normal(&quot;u_diff&quot;, mu=0.0, sigma=0.1, dims=&quot;timesteps&quot;) u_uncert = stdz_log_unemployment + u_diff # overdispersion parameter theta = pm.Exponential(&quot;theta_offset&quot;, 1.0) + 10.0 p = pm.Deterministic( &quot;p&quot;, pm.math.invlogit( baseline + f_time + honeymoon * election_flag + log_unemp_effect * u_uncert ), dims=&quot;timesteps&quot;, ) y = pm.BetaBinomial( &quot;y&quot;, alpha=p * theta, beta=(1.0 - p) * theta, n=d.N_total, observed=d.N_approve, dims=&quot;timesteps&quot;, ) . with econ_latent_gp: trace_econ = pm.sample( draws=2000, chains=8, cores=8, return_inferencedata=True, idata_kwargs={ &quot;dims&quot;: {&quot;f_time&quot;: [&quot;timesteps&quot;], &quot;f_time_rotated_&quot;: [&quot;timesteps&quot;]} }, ) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Multiprocess sampling (8 chains in 8 jobs) NUTS: [theta_offset, u_diff, f_time_rotated_, ls_trend, amplitude_trend, log_unemp_effect, honeymoon, baseline] . . 100.00% [24000/24000 19:45&lt;00:00 Sampling 8 chains, 0 divergences] Sampling 8 chains for 1_000 tune and 2_000 draw iterations (8_000 + 16_000 draws total) took 1202 seconds. . az.summary( trace_econ, var_names=[&quot;~u_diff&quot;, &quot;~p&quot;, &quot;~f_time&quot;, &quot;~f_time_rotated_&quot;], round_to=2 ) . mean sd hdi_3% hdi_97% mcse_mean mcse_sd ess_mean ess_sd ess_bulk ess_tail r_hat . baseline -0.54 | 0.11 | -0.75 | -0.33 | 0.00 | 0.00 | 11032.88 | 10531.30 | 11332.08 | 9104.29 | 1.0 | . honeymoon 0.37 | 0.14 | 0.11 | 0.63 | 0.00 | 0.00 | 25628.14 | 21963.41 | 25654.04 | 11571.46 | 1.0 | . log_unemp_effect -0.12 | 0.07 | -0.26 | 0.02 | 0.00 | 0.00 | 11594.78 | 11594.78 | 11697.90 | 9922.54 | 1.0 | . amplitude_trend 0.43 | 0.07 | 0.32 | 0.56 | 0.00 | 0.00 | 5574.96 | 5215.63 | 6164.58 | 6890.74 | 1.0 | . ls_trend 6.17 | 1.01 | 4.39 | 8.11 | 0.01 | 0.01 | 5601.72 | 5426.55 | 5836.45 | 7198.35 | 1.0 | . theta_offset 50.41 | 6.55 | 38.65 | 63.15 | 0.05 | 0.04 | 17198.27 | 16606.33 | 17395.18 | 11463.88 | 1.0 | . az.plot_trace( trace_econ, compact=True, var_names=[&quot;~u_diff&quot;, &quot;~p&quot;, &quot;~f_time&quot;, &quot;~f_time_rotated_&quot;] ); . az.plot_trace( trace_econ, var_names=[&quot;u_diff&quot;, &quot;p&quot;, &quot;f_time&quot;], compact=True, coords={&quot;timesteps&quot;: trace_econ.observed_data.timesteps[:110]}, ); . az.plot_trace( trace_econ, var_names=[&quot;u_diff&quot;, &quot;p&quot;, &quot;f_time&quot;], compact=True, coords={&quot;timesteps&quot;: trace_econ.observed_data.timesteps[110:]}, ); . . az.plot_pair( trace_econ, var_names=[&quot;~u_diff&quot;, &quot;~p&quot;, &quot;~f_time&quot;, &quot;~f_time_rotated_&quot;], divergences=True, ); . az.plot_rank(trace_econ, var_names=[&quot;~u_diff&quot;, &quot;~p&quot;, &quot;~f_time&quot;, &quot;~f_time_rotated_&quot;]); . az.plot_parallel(trace_econ, var_names=[&quot;~u_diff&quot;, &quot;~p&quot;, &quot;~f_time&quot;, &quot;~f_time_rotated_&quot;]); . MAX_OBSERVED = len(d.index) TIME_BEFORE_ORIGIN = 0 MAX_TIME = MAX_OBSERVED + 3 # 1 quarter out-of-sample RANGE_OOS = MAX_TIME + TIME_BEFORE_ORIGIN tnew = np.linspace(-TIME_BEFORE_ORIGIN, MAX_TIME, RANGE_OOS)[:, None] . log_unemp = np.log(d.unemployment) # unemployment stays around last value ppc_unemp = np.random.normal( loc=d.unemployment.iloc[-1], scale=d.unemployment.std(), size=(MAX_TIME - MAX_OBSERVED) // 3, ) # data only observed quarterly, so need to forward-fill ppc_unemp = np.repeat(ppc_unemp, repeats=3) # log data and scale stdz_log_ppc_unemp = (np.log(ppc_unemp) - log_unemp.mean()) / log_unemp.std() # add noise around values oos_unemp = stdz_log_ppc_unemp + np.random.normal( loc=trace_econ.posterior[&quot;u_diff&quot;].mean(), scale=trace_econ.posterior[&quot;u_diff&quot;].std(), size=MAX_TIME - MAX_OBSERVED, ) oos_unemp . array([-0.26766595, -0.04889151, 0.08842622]) . ppc_unemp_10 = np.random.normal( loc=10.0, scale=d.unemployment.std(), size=(MAX_TIME - MAX_OBSERVED) // 3 ) # data only observed quarterly, so need to forward-fill ppc_unemp_10 = np.repeat(ppc_unemp_10, repeats=3) # log data and scale stdz_log_ppc_unemp_10 = (np.log(ppc_unemp_10) - log_unemp.mean()) / log_unemp.std() # add noise around values oos_unemp_10 = stdz_log_ppc_unemp_10 + np.random.normal( loc=trace_econ.posterior[&quot;u_diff&quot;].mean(), scale=trace_econ.posterior[&quot;u_diff&quot;].std(), size=MAX_TIME - MAX_OBSERVED, ) oos_unemp_10 . array([0.99334796, 1.34851993, 0.91794086]) . ppc_unemp_5 = np.random.normal( loc=5.0, scale=d.unemployment.std(), size=(MAX_TIME - MAX_OBSERVED) // 3 ) # data only observed quarterly, so need to forward-fill ppc_unemp_5 = np.repeat(ppc_unemp_5, repeats=3) # log data and scale stdz_log_ppc_unemp_5 = (np.log(ppc_unemp_5) - log_unemp.mean()) / log_unemp.std() # add noise around values oos_unemp_5 = stdz_log_ppc_unemp_5 + np.random.normal( loc=trace_econ.posterior[&quot;u_diff&quot;].mean(), scale=trace_econ.posterior[&quot;u_diff&quot;].std(), size=MAX_TIME - MAX_OBSERVED, ) oos_unemp_5 . array([-4.75148576, -4.79732956, -4.80334542]) . /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/pymc3/sampling.py:1707: UserWarning: samples parameter is smaller than nchains times ndraws, some draws and/or chains may not be represented in the returned posterior predictive sample warnings.warn( . . 100.00% [1000/1000 03:57&lt;00:00] arviz.InferenceData posterior . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (chain: 8, draw: 2000, timesteps: 224) Coordinates: * chain (chain) int64 0 1 2 3 4 5 6 7 * draw (draw) int64 0 1 2 3 4 5 ... 1994 1995 1996 1997 1998 1999 * timesteps (timesteps) datetime64[ns] 2002-05-31 ... 2020-12-31 Data variables: baseline (chain, draw) float64 -0.4363 -0.4857 ... -0.5925 -0.5848 honeymoon (chain, draw) float64 0.1909 0.4704 ... 0.5109 0.4024 log_unemp_effect (chain, draw) float64 -0.1278 -0.0196 ... -0.1781 -0.1067 f_time_rotated_ (chain, draw, timesteps) float64 0.9506 0.1954 ... 1.346 u_diff (chain, draw, timesteps) float64 -0.06023 ... -0.01508 amplitude_trend (chain, draw) float64 0.421 0.3564 0.4082 ... 0.313 0.3946 ls_trend (chain, draw) float64 5.211 5.549 8.358 ... 4.605 4.907 f_time (chain, draw, timesteps) float64 0.4002 0.4083 ... 0.1658 theta_offset (chain, draw) float64 44.52 46.07 43.79 ... 55.16 63.14 p (chain, draw, timesteps) float64 0.5862 0.5394 ... 0.3934 Attributes: created_at: 2021-01-06T18:05:36.485625 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 sampling_time: 1202.0958020687103 tuning_steps: 1000 . xarray.DatasetDimensions:chain: 8 | draw: 2000 | timesteps: 224 | . | Coordinates: (3)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7]) . | draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([ 0, 1, 2, ..., 1997, 1998, 1999]) . | timesteps(timesteps)datetime64[ns]2002-05-31 ... 2020-12-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2020-10-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-11-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-12-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (10)baseline(chain, draw)float64-0.4363 -0.4857 ... -0.5925 -0.5848array([[-0.436259, -0.485742, -0.528613, ..., -0.644816, -0.580835, -0.620202], [-0.533794, -0.459574, -0.55348 , ..., -0.715371, -0.421032, -0.498974], [-0.443912, -0.442 , -0.642637, ..., -0.265354, -0.523603, -0.616659], ..., [-0.393301, -0.528154, -0.622709, ..., -0.481435, -0.467518, -0.580904], [-0.498099, -0.578654, -0.582178, ..., -0.589289, -0.454625, -0.492596], [-0.436576, -0.665019, -0.417993, ..., -0.393182, -0.592511, -0.584823]]) . | honeymoon(chain, draw)float640.1909 0.4704 ... 0.5109 0.4024array([[0.190864, 0.470408, 0.361856, ..., 0.47545 , 0.292357, 0.5337 ], [0.438198, 0.427164, 0.343319, ..., 0.261422, 0.381605, 0.31927 ], [0.386569, 0.3883 , 0.436878, ..., 0.399517, 0.179216, 0.478767], ..., [0.221822, 0.504441, 0.157388, ..., 0.280806, 0.24611 , 0.352064], [0.453058, 0.452927, 0.450296, ..., 0.340168, 0.513379, 0.231442], [0.407092, 0.326461, 0.262517, ..., 0.198765, 0.510929, 0.402446]]) . | log_unemp_effect(chain, draw)float64-0.1278 -0.0196 ... -0.1781 -0.1067array([[-0.127842, -0.019597, -0.192493, ..., -0.220829, -0.250949, -0.169671], [-0.1565 , -0.053148, -0.108868, ..., -0.120876, -0.160784, -0.044106], [-0.251744, -0.108639, -0.097324, ..., -0.225344, -0.140035, -0.13312 ], ..., [-0.127213, 0.056558, -0.024484, ..., -0.043219, -0.035149, -0.104047], [-0.224514, -0.053611, -0.086919, ..., -0.09792 , -0.301924, -0.113712], [-0.166196, -0.102762, -0.166915, ..., -0.132634, -0.178125, -0.106693]]) . | f_time_rotated_(chain, draw, timesteps)float640.9506 0.1954 ... 0.4004 1.346array([[[ 0.950646, 0.195439, ..., -1.052328, 0.817676], [ 0.983399, 1.510631, ..., 0.985234, 0.325607], ..., [ 0.335665, 1.227786, ..., -1.137537, 0.269766], [ 0.545266, 0.864439, ..., -0.367222, -0.172578]], [[ 0.43719 , 0.992374, ..., -0.77966 , 0.451844], [ 0.482052, 1.380805, ..., 0.319254, 0.760911], ..., [ 0.287753, 0.125225, ..., -0.781442, 0.540605], [ 0.874419, 2.503457, ..., 0.007137, -0.54956 ]], ..., [[ 0.971334, 0.488052, ..., 0.533251, 0.043281], [ 0.815223, 1.910508, ..., -0.922402, -0.615418], ..., [-0.616881, 1.804229, ..., 0.937184, 0.320834], [ 0.923818, 0.410182, ..., -1.243298, -0.790733]], [[ 0.312341, 0.472087, ..., 1.734468, 0.123808], [ 0.989922, 2.135634, ..., -2.065482, -1.055105], ..., [ 1.113864, -0.03784 , ..., -1.51313 , 0.825069], [ 1.230489, 1.243667, ..., 0.400369, 1.345886]]]) . | u_diff(chain, draw, timesteps)float64-0.06023 -0.003396 ... -0.01508array([[[-6.022997e-02, -3.395535e-03, ..., 6.800054e-04, -3.170496e-02], [-1.396880e-03, -2.073526e-03, ..., -8.475390e-02, -9.184962e-03], ..., [ 9.083372e-02, -1.360849e-01, ..., -1.188281e-02, -6.459683e-04], [ 1.190198e-01, -4.231976e-02, ..., 6.013837e-02, 4.115094e-02]], [[-1.308783e-02, 8.385609e-03, ..., 5.515290e-02, 1.607988e-01], [ 1.223986e-01, -5.261157e-02, ..., -2.617064e-02, -1.073415e-01], ..., [-1.495714e-02, 1.631528e-01, ..., -3.766275e-02, -4.977028e-02], [ 1.957986e-01, -1.266575e-01, ..., 1.666177e-01, -9.004046e-02]], ..., [[ 1.315382e-01, -2.011854e-02, ..., 3.618980e-03, -2.217502e-02], [-1.392248e-01, 2.540199e-02, ..., -1.984890e-05, -8.418250e-02], ..., [ 1.305115e-01, 8.286949e-02, ..., -6.896835e-02, 8.205686e-02], [-1.553330e-01, -1.069568e-01, ..., 3.291380e-03, -3.473805e-02]], [[ 3.233602e-03, 1.853850e-01, ..., -6.907486e-02, -3.217008e-02], [-1.173682e-01, -1.229269e-01, ..., 7.470020e-02, 6.304431e-02], ..., [-5.474015e-03, -3.464282e-03, ..., 2.672296e-02, 4.926155e-02], [ 9.417050e-02, -8.875466e-02, ..., -3.726494e-03, -1.508422e-02]]]) . | amplitude_trend(chain, draw)float640.421 0.3564 ... 0.313 0.3946array([[0.420971, 0.356352, 0.408193, ..., 0.383418, 0.41213 , 0.405001], [0.3571 , 0.488905, 0.446752, ..., 0.376734, 0.347576, 0.365032], [0.345825, 0.518582, 0.494144, ..., 0.494292, 0.363077, 0.344392], ..., [0.441311, 0.531136, 0.485347, ..., 0.572476, 0.55011 , 0.471062], [0.42342 , 0.436554, 0.395399, ..., 0.321121, 0.40584 , 0.395068], [0.392957, 0.366723, 0.613363, ..., 0.421592, 0.312983, 0.394645]]) . | ls_trend(chain, draw)float645.211 5.549 8.358 ... 4.605 4.907array([[5.210559, 5.549456, 8.357902, ..., 5.06031 , 4.931608, 5.146909], [5.582152, 6.286212, 7.154772, ..., 8.02208 , 5.210963, 5.394312], [6.641617, 6.128056, 5.468974, ..., 5.953983, 6.252206, 5.114916], ..., [5.029831, 6.328448, 8.415503, ..., 5.420145, 5.724496, 5.974534], [8.202474, 6.664928, 6.30314 , ..., 4.354075, 5.191838, 5.738356], [5.798896, 6.36093 , 6.059703, ..., 6.265174, 4.60458 , 4.907146]]) . | f_time(chain, draw, timesteps)float640.4002 0.4083 ... 0.03135 0.1658array([[[ 0.400195, 0.408276, ..., 0.185789, 0.109822], [ 0.350438, 0.462202, ..., 0.093406, 0.161026], ..., [ 0.138338, 0.260853, ..., 0.197228, 0.111765], [ 0.220834, 0.298666, ..., 0.378496, 0.363078]], [[ 0.156121, 0.231193, ..., 0.282032, 0.302617], [ 0.235678, 0.365204, ..., 0.027598, 0.044265], ..., [ 0.100017, 0.107503, ..., -0.165138, -0.168689], [ 0.319193, 0.521112, ..., 0.099088, 0.096649]], ..., [[ 0.411283, 0.438128, ..., 0.038211, 0.065956], [ 0.35589 , 0.506266, ..., 0.024387, -0.058167], ..., [-0.250356, -0.068174, ..., -0.151779, -0.077522], [ 0.364972, 0.391449, ..., -0.076989, -0.198185]], [[ 0.122737, 0.159739, ..., -0.164904, -0.124052], [ 0.363029, 0.509916, ..., 0.226586, 0.11639 ], ..., [ 0.348622, 0.33273 , ..., -0.071952, -0.100477], [ 0.485609, 0.593639, ..., 0.031346, 0.165834]]]) . | theta_offset(chain, draw)float6444.52 46.07 43.79 ... 55.16 63.14array([[44.517786, 46.066267, 43.787085, ..., 54.281168, 59.657614, 53.018371], [57.957796, 36.739866, 58.02422 , ..., 44.950503, 51.547959, 48.044256], [44.371318, 52.19786 , 53.237135, ..., 55.638005, 43.791919, 48.167027], ..., [55.874401, 52.686891, 45.725033, ..., 49.458284, 48.749905, 54.398586], [47.4572 , 52.135028, 51.318756, ..., 48.198641, 47.573957, 46.927469], [37.351627, 43.528549, 55.725732, ..., 43.410412, 55.155819, 63.140727]]) . | p(chain, draw, timesteps)float640.5862 0.5394 ... 0.3615 0.3934array([[[0.586174, 0.539449, ..., 0.433084, 0.41554 ], [0.58991 , 0.501241, ..., 0.402864, 0.418872], ..., [0.547737, 0.519649, ..., 0.397144, 0.37621 ], [0.589176, 0.483023, ..., 0.431248, 0.428259]], [[0.571964, 0.480855, ..., 0.429641, 0.430634], [0.568063, 0.496404, ..., 0.39213 , 0.397142], ..., [0.573589, 0.473464, ..., 0.353506, 0.353139], [0.548574, 0.52293 , ..., 0.398027, 0.400156]], ..., [[0.659885, 0.567245, ..., 0.37905 , 0.386974], [0.578225, 0.501028, ..., 0.363058, 0.34521 ], ..., [0.551688, 0.472698, ..., 0.347555, 0.354082], [0.571171, 0.519032, ..., 0.357412, 0.33104 ]], [[0.582755, 0.483438, ..., 0.351069, 0.359019], [0.546312, 0.501694, ..., 0.38671 , 0.3612 ], ..., [0.628717, 0.499884, ..., 0.332852, 0.325666], [0.610197, 0.543202, ..., 0.361535, 0.393409]]]) . | . | Attributes: (6)created_at :2021-01-06T18:05:36.485625arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3sampling_time :1202.0958020687103tuning_steps :1000 | . . | predictions . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (chain: 1, draw: 1000, timesteps: 227) Coordinates: * chain (chain) int64 0 * draw (draw) int64 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999 * timesteps (timesteps) datetime64[ns] 2002-05-31 ... 2021-03-31 Data variables: baseline (chain, draw) float64 -0.4363 -0.4857 ... -0.4203 -0.6564 f_time_new (chain, draw, timesteps) float64 0.4005 0.4078 ... 0.2904 honeymoon (chain, draw) float64 0.1909 0.4704 0.3619 ... 0.5143 0.17 log_unemp_effect (chain, draw) float64 -0.1278 -0.0196 ... -0.09647 -0.1405 Attributes: created_at: 2021-01-12T17:44:53.340684 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 . xarray.DatasetDimensions:chain: 1 | draw: 1000 | timesteps: 227 | . | Coordinates: (3)chain(chain)int640array([0]) . | draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([ 0, 1, 2, ..., 997, 998, 999]) . | timesteps(timesteps)datetime64[ns]2002-05-31 ... 2021-03-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2021-01-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2021-02-28T00:00:00.000000000&amp;#x27;, &amp;#x27;2021-03-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (4)baseline(chain, draw)float64-0.4363 -0.4857 ... -0.4203 -0.6564array([[-0.43625879, -0.48574161, -0.5286134 , -0.64559493, -0.59248196, -0.55291359, -0.58067543, -0.58960307, -0.40461416, -0.6905615 , -0.52110386, -0.62212693, -0.52295147, -0.4885803 , -0.51130152, -0.53187818, -0.57608249, -0.57694626, -0.4544789 , -0.42242123, -0.39292794, -0.55719715, -0.44001401, -0.65856946, -0.59569688, -0.52140946, -0.48768669, -0.41500347, -0.73824238, -0.4926808 , -0.39956783, -0.39956783, -0.39956783, -0.39956783, -0.45034604, -0.30344626, -0.30096487, -0.32167618, -0.66616313, -0.60202469, -0.53283448, -0.54485486, -0.52618402, -0.83917803, -0.65955219, -0.50504171, -0.76597463, -0.74424522, -0.86701604, -0.65815014, -0.57485339, -0.53946589, -0.37853226, -0.59741236, -0.62345836, -0.61491188, -0.44165921, -0.57639525, -0.48049439, -0.44329428, -0.44835599, -0.58519946, -0.58857492, -0.48393697, -0.74843286, -0.43571422, -0.48136848, -0.67124302, -0.63419994, -0.62892936, -0.40168179, -0.59621003, -0.57313415, -0.59532665, -0.54264657, -0.39950621, -0.60034897, -0.37859908, -0.53489498, -0.60300625, -0.49584792, -0.56943363, -0.50128409, -0.49901539, -0.36532683, -0.75976793, -0.62645217, -0.64122141, -0.38841944, -0.50821595, -0.37018688, -0.39869391, -0.48826931, -0.544026 , -0.51143677, -0.51948063, -0.50434467, -0.45722365, -0.67559412, -0.52714334, ... -0.67555032, -0.47103141, -0.57642552, -0.54374424, -0.5048895 , -0.49519281, -0.60495979, -0.4444632 , -0.58710536, -0.46822319, -0.45465928, -0.42929717, -0.42737273, -0.68099299, -0.6090337 , -0.64640853, -0.57393904, -0.54592797, -0.52724363, -0.55675102, -0.64735438, -0.68982888, -0.6411461 , -0.64425712, -0.72524526, -0.59597006, -0.58960573, -0.75570483, -0.36434818, -0.5449154 , -0.48718284, -0.39128929, -0.48676933, -0.49832059, -0.44932242, -0.57272027, -0.43481085, -0.41535228, -0.61068977, -0.5009862 , -0.72324705, -0.41225526, -0.56490182, -0.58398767, -0.38732753, -0.521981 , -0.57232234, -0.47755669, -0.5452063 , -0.59486016, -0.55991105, -0.62241331, -0.63749299, -0.36554085, -0.43024398, -0.35861431, -0.67429745, -0.36107275, -0.71148826, -0.36641749, -0.62355093, -0.6440689 , -0.48048384, -0.45635292, -0.61975745, -0.51633906, -0.42811206, -0.61867792, -0.65764058, -0.71933331, -0.57555688, -0.68270761, -0.35770065, -0.4017272 , -0.47928941, -0.33624455, -0.51588949, -0.71102188, -0.75313719, -0.71577672, -0.53899604, -0.58202498, -0.4700705 , -0.5650992 , -0.55145086, -0.51272132, -0.45890297, -0.46968444, -0.67231695, -0.42672777, -0.43687954, -0.43687954, -0.48676753, -0.56681637, -0.59393669, -0.4489957 , -0.5054185 , -0.57789603, -0.42033187, -0.65641667]]) . | f_time_new(chain, draw, timesteps)float640.4005 0.4078 ... 0.2759 0.2904array([[[ 0.40048154, 0.4078173 , 0.49528921, ..., 0.20175192, 0.36213709, 0.5284349 ], [ 0.3501626 , 0.46415328, 0.55896717, ..., 0.16747804, 0.14902776, 0.18470871], [ 0.5184999 , 0.53494914, 0.54854685, ..., 0.04293233, -0.01021009, -0.05930939], ..., [ 0.3420291 , 0.43342557, 0.52991456, ..., -0.003684 , 0.08158937, 0.1664917 ], [ 0.17500543, 0.24687143, 0.29640748, ..., 0.08857997, 0.02582052, -0.03356664], [ 0.4028973 , 0.48486352, 0.59517899, ..., 0.21203412, 0.27587441, 0.29037908]]]) . | honeymoon(chain, draw)float640.1909 0.4704 ... 0.5143 0.17array([[ 0.1908639 , 0.47040813, 0.36185571, 0.2856977 , 0.3811378 , 0.36244583, 0.10311861, 0.1080859 , 0.03328846, 0.47565993, 0.22268568, 0.34460275, 0.37563594, 0.4894104 , 0.38797892, 0.41721584, 0.37837492, 0.33744021, 0.40028533, 0.40616182, 0.29423874, 0.39389715, 0.45110294, 0.32668074, 0.50253016, 0.29385728, 0.50959849, 0.36326703, 0.35404129, 0.54475217, 0.41317489, 0.41317489, 0.41317489, 0.41317489, 0.41503455, 0.30143191, 0.31789927, 0.58540484, 0.22980187, 0.41264497, 0.4827313 , 0.22597252, 0.23016728, 0.38321951, 0.30944118, 0.31908338, 0.36872333, 0.35263877, 0.30185742, 0.67036065, 0.26964418, 0.4489402 , 0.27236298, 0.41332224, 0.34318864, 0.50313252, 0.27817268, 0.30865052, 0.37014364, 0.32391028, 0.47826365, 0.31993823, 0.41563935, 0.31148711, 0.10734379, 0.54772024, 0.6501007 , 0.20362355, 0.40711657, 0.17021074, 0.57917167, 0.19338378, 0.4841949 , 0.2632464 , 0.40861572, 0.48938794, 0.28690878, 0.54379596, 0.11292878, 0.62557569, 0.06984832, 0.46807049, 0.35098721, 0.30181487, 0.47949582, 0.37317188, 0.32877068, 0.37915395, 0.39283594, 0.25164021, 0.20363534, 0.36335523, 0.34998194, 0.19058993, 0.43412936, 0.32931882, 0.52805403, 0.4711375 , 0.04262981, 0.62065003, ... 0.38930806, 0.33189326, 0.53420513, 0.46452816, 0.3853261 , 0.32013199, 0.35968226, 0.49327233, 0.26387218, 0.30334486, 0.43788458, 0.23770343, 0.30806205, 0.45045212, 0.45495432, 0.19202458, 0.27834164, 0.32745465, 0.41208555, 0.27359078, 0.57813017, 0.39979046, 0.4422062 , 0.46611387, 0.41028903, 0.37979087, 0.39378455, 0.42200883, 0.16456977, 0.51498907, 0.30743382, 0.22969242, 0.28088432, 0.09780479, 0.51209448, 0.17155896, 0.59428534, 0.45597454, 0.37870565, 0.5518397 , 0.46014876, 0.32318944, 0.48230991, 0.27317061, 0.37737394, 0.30846902, 0.43220933, 0.41092896, 0.48875788, 0.25083671, 0.42327869, 0.37086677, 0.38152618, 0.40906381, 0.38168796, 0.49474121, 0.18401238, 0.40287677, 0.40108102, 0.27850057, 0.45025293, 0.3753706 , 0.47173744, 0.19492201, 0.42732349, 0.30180908, 0.33143233, 0.47082153, 0.33456935, 0.45155229, 0.15056518, 0.40378881, 0.34087757, 0.51063793, 0.25162084, 0.5054239 , 0.19706312, 0.51235224, 0.36674645, 0.35301964, 0.31169924, 0.30188158, 0.51538477, 0.36727033, 0.371483 , 0.08854247, 0.5049214 , 0.30323464, 0.60702031, 0.23857475, 0.49525868, 0.49525868, 0.38395199, 0.19597332, 0.38046489, 0.43854579, 0.41124523, 0.28073884, 0.51430346, 0.16996953]]) . | log_unemp_effect(chain, draw)float64-0.1278 -0.0196 ... -0.1405array([[-1.27842301e-01, -1.95969956e-02, -1.92492952e-01, 4.41295238e-02, -5.09673974e-02, -5.86975354e-02, -3.84469303e-02, -4.26598467e-02, -9.37154737e-02, -2.34704884e-01, -2.34420474e-02, -1.78137449e-01, -7.67201055e-02, -8.18415581e-02, -1.04498420e-01, -1.75132306e-01, -1.18396697e-01, -3.60893799e-02, -1.12962962e-01, -1.79460873e-01, -2.24442576e-01, -1.13777335e-01, -1.32075763e-01, -2.22831059e-01, -1.87147566e-01, -2.27924737e-01, -7.08693066e-02, -1.59878672e-01, -2.61146344e-02, -1.25423363e-01, -9.21556806e-02, -9.21556806e-02, -9.21556806e-02, -9.21556806e-02, -7.37771476e-02, -5.26882136e-03, -1.10402867e-01, -2.67619019e-01, 3.30107778e-02, -1.21686594e-01, -1.58823954e-02, -9.45069738e-02, -1.16491808e-01, -1.81251149e-01, 5.49677908e-02, -1.41481588e-01, 1.38871908e-02, -4.07843443e-02, -1.35667297e-01, 1.76752612e-02, -1.53813849e-01, -1.56162060e-01, -1.20025413e-01, -1.63580931e-01, 4.21139080e-02, -2.39489501e-01, -4.62005098e-02, -1.36811617e-01, -9.52009002e-02, -1.14098637e-01, ... -1.08735277e-01, -1.60223877e-01, -3.43716530e-01, -6.69420799e-02, -2.87161404e-01, -4.28354871e-02, -8.84978002e-02, -7.89739444e-02, -1.41107072e-01, -3.05011091e-02, -1.29120833e-01, -5.31560311e-02, -1.37996877e-01, -1.14779244e-01, -2.48461318e-01, -1.61949441e-02, -2.01423868e-01, -1.64550955e-01, -5.62484471e-02, -1.44885764e-01, -2.47262927e-01, -1.97678118e-01, -2.29837557e-01, -7.48490609e-02, -1.64742757e-01, -1.40862839e-01, -1.10609331e-01, -2.25123533e-01, -9.50643050e-02, -1.28917440e-01, -1.24567666e-01, -1.73881826e-01, -9.05988295e-02, 8.84661162e-03, -1.31806254e-01, -3.84842211e-03, -1.78692155e-02, -1.44202210e-01, -2.93315736e-03, -1.45309638e-01, -6.20651960e-02, -2.63994258e-01, -2.47047274e-01, -3.41059582e-03, -4.38962270e-02, -3.14917057e-02, -8.71898328e-02, -2.04190328e-01, -6.93481798e-02, -6.93481798e-02, 6.14547126e-03, -1.78796162e-01, -2.08948229e-01, 9.29537350e-03, -6.35423546e-02, -1.07177710e-01, -9.64654392e-02, -1.40491546e-01]]) . | . | Attributes: (4)created_at :2021-01-12T17:44:53.340684arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3 | . . | log_likelihood . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (chain: 8, draw: 2000, timesteps: 224) Coordinates: * chain (chain) int64 0 1 2 3 4 5 6 7 * draw (draw) int64 0 1 2 3 4 5 6 ... 1993 1994 1995 1996 1997 1998 1999 * timesteps (timesteps) datetime64[ns] 2002-05-31 2002-06-30 ... 2020-12-31 Data variables: y (chain, draw, timesteps) float64 ... Attributes: created_at: 2021-01-06T18:06:00.288873 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 . xarray.DatasetDimensions:chain: 8 | draw: 2000 | timesteps: 224 | . | Coordinates: (3)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7]) . | draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([ 0, 1, 2, ..., 1997, 1998, 1999]) . | timesteps(timesteps)datetime64[ns]2002-05-31 ... 2020-12-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2020-10-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-11-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-12-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (1)y(chain, draw, timesteps)float64...[3584000 values with dtype=float64] . | . | Attributes: (4)created_at :2021-01-06T18:06:00.288873arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3 | . . | sample_stats . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (chain: 8, draw: 2000) Coordinates: * chain (chain) int64 0 1 2 3 4 5 6 7 * draw (draw) int64 0 1 2 3 4 5 ... 1995 1996 1997 1998 1999 Data variables: max_energy_error (chain, draw) float64 0.7922 -1.559 ... -1.594 -0.9592 lp (chain, draw) float64 -1.356e+03 -1.39e+03 ... -1.35e+03 perf_counter_start (chain, draw) float64 480.4 480.8 ... 1.142e+03 process_time_diff (chain, draw) float64 0.5495 0.5557 ... 0.5747 0.5738 depth (chain, draw) int64 5 5 5 5 5 5 5 5 ... 5 5 5 5 5 5 5 5 perf_counter_diff (chain, draw) float64 0.3534 0.3601 ... 0.2366 0.2361 mean_tree_accept (chain, draw) float64 0.8875 0.9967 ... 0.9802 0.9488 step_size (chain, draw) float64 0.1437 0.1437 ... 0.1409 0.1409 energy (chain, draw) float64 1.555e+03 1.603e+03 ... 1.589e+03 energy_error (chain, draw) float64 0.7922 -0.1915 ... -0.3758 -0.4199 diverging (chain, draw) bool False False False ... False False tree_size (chain, draw) float64 31.0 31.0 31.0 ... 31.0 31.0 31.0 step_size_bar (chain, draw) float64 0.163 0.163 ... 0.1555 0.1555 Attributes: created_at: 2021-01-06T18:05:36.497940 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 sampling_time: 1202.0958020687103 tuning_steps: 1000 . xarray.DatasetDimensions:chain: 8 | draw: 2000 | . | Coordinates: (2)chain(chain)int640 1 2 3 4 5 6 7array([0, 1, 2, 3, 4, 5, 6, 7]) . | draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([ 0, 1, 2, ..., 1997, 1998, 1999]) . | . | Data variables: (13)max_energy_error(chain, draw)float64...array([[ 0.792154, -1.558606, -1.79934 , ..., 1.383167, -1.060689, 0.964015], [ 0.759627, -0.976008, -1.113724, ..., -1.286735, -1.15211 , -0.649953], [ 2.178466, -2.039393, 0.780307, ..., 1.775666, 2.313681, 1.152 ], ..., [-0.739115, 1.065137, 3.00161 , ..., -2.43775 , 1.30729 , 1.868844], [-1.121168, -0.662315, -1.129057, ..., 0.804497, -1.142428, -1.048159], [ 1.332624, 0.675142, -1.581437, ..., -1.989439, -1.593931, -0.959229]]) . | lp(chain, draw)float64...array([[-1355.717078, -1389.789911, -1385.346915, ..., -1351.511362, -1322.168334, -1351.251799], [-1348.856642, -1342.953601, -1342.015424, ..., -1366.55431 , -1363.405891, -1352.05766 ], [-1347.955942, -1330.501772, -1348.719031, ..., -1350.477201, -1339.340424, -1337.728731], ..., [-1346.979869, -1339.795672, -1353.553042, ..., -1303.356286, -1300.774805, -1333.702498], [-1335.630121, -1324.063168, -1336.779128, ..., -1364.134197, -1362.162345, -1352.949485], [-1324.998974, -1327.758254, -1336.016593, ..., -1372.014891, -1365.222772, -1350.334596]]) . | perf_counter_start(chain, draw)float64...array([[ 480.420509, 480.774338, 481.134791, ..., 1146.848359, 1147.060405, 1147.278788], [ 523.289166, 523.69238 , 524.127457, ..., 1167.585508, 1167.698378, 1167.811564], [ 514.078334, 514.400392, 514.73053 , ..., 1164.241936, 1164.39751 , 1164.553234], ..., [ 468.179194, 468.5533 , 468.920698, ..., 1137.867044, 1138.150259, 1138.430388], [ 516.277621, 516.600169, 516.938501, ..., 1165.147727, 1165.326703, 1165.492426], [ 474.669731, 475.04417 , 475.442347, ..., 1141.874933, 1142.108928, 1142.345839]]) . | process_time_diff(chain, draw)float64...array([[0.549494, 0.555667, 0.56314 , ..., 0.601862, 0.607756, 0.599651], [0.697427, 0.721565, 0.589913, ..., 0.889321, 0.897089, 0.88038 ], [0.577492, 0.574852, 0.580045, ..., 0.676707, 0.676789, 0.661583], ..., [0.597366, 0.587376, 0.59058 , ..., 0.589338, 0.579674, 0.599307], [0.569152, 0.58312 , 0.569636, ..., 0.73278 , 0.742584, 0.765797], [0.647393, 0.684296, 0.611627, ..., 0.571308, 0.574692, 0.573753]]) . | depth(chain, draw)int64...array([[5, 5, 5, ..., 5, 5, 5], [5, 5, 5, ..., 5, 5, 5], [5, 5, 5, ..., 5, 5, 5], ..., [5, 5, 5, ..., 5, 5, 5], [5, 5, 5, ..., 5, 5, 5], [5, 5, 5, ..., 5, 5, 5]]) . | perf_counter_diff(chain, draw)float64...array([[0.353436, 0.360064, 0.321407, ..., 0.211714, 0.218032, 0.211152], [0.402811, 0.434758, 0.327091, ..., 0.112606, 0.112922, 0.111253], [0.321665, 0.329798, 0.327542, ..., 0.155282, 0.155438, 0.165221], ..., [0.373692, 0.367025, 0.340378, ..., 0.2829 , 0.279777, 0.308766], [0.322105, 0.33793 , 0.329492, ..., 0.178657, 0.165413, 0.154259], [0.374003, 0.39785 , 0.333066, ..., 0.233589, 0.236603, 0.236098]]) . | mean_tree_accept(chain, draw)float64...array([[0.887549, 0.996668, 0.989418, ..., 0.798561, 0.988912, 0.780693], [0.830962, 0.837476, 0.973682, ..., 0.953519, 0.982599, 0.972599], [0.808065, 0.970672, 0.819558, ..., 0.756983, 0.381697, 0.658867], ..., [0.972668, 0.807989, 0.404268, ..., 0.998987, 0.770929, 0.760289], [0.96556 , 0.97902 , 0.929397, ..., 0.746068, 0.988615, 0.998938], [0.856465, 0.857914, 0.853603, ..., 0.85993 , 0.980202, 0.948789]]) . | step_size(chain, draw)float64...array([[0.143669, 0.143669, 0.143669, ..., 0.143669, 0.143669, 0.143669], [0.175321, 0.175321, 0.175321, ..., 0.175321, 0.175321, 0.175321], [0.171155, 0.171155, 0.171155, ..., 0.171155, 0.171155, 0.171155], ..., [0.153403, 0.153403, 0.153403, ..., 0.153403, 0.153403, 0.153403], [0.168901, 0.168901, 0.168901, ..., 0.168901, 0.168901, 0.168901], [0.140922, 0.140922, 0.140922, ..., 0.140922, 0.140922, 0.140922]]) . | energy(chain, draw)float64...array([[1554.910153, 1602.604333, 1627.380433, ..., 1570.853919, 1549.583166, 1561.57105 ], [1575.592038, 1570.399586, 1568.38023 , ..., 1584.745551, 1597.675961, 1585.452724], [1572.58742 , 1573.91304 , 1587.038142, ..., 1578.331395, 1576.920882, 1595.479696], ..., [1591.848449, 1561.923902, 1569.658261, ..., 1523.733749, 1526.698761, 1519.037709], [1552.352728, 1583.170259, 1540.766186, ..., 1608.598199, 1571.390576, 1604.763946], [1541.161919, 1564.6878 , 1543.621769, ..., 1590.228835, 1583.778415, 1588.751211]]) . | energy_error(chain, draw)float64...array([[ 0.792154, -0.191505, -1.009606, ..., -0.48897 , -1.060689, 0.128793], [ 0.332561, -0.194617, -0.351468, ..., 0.381118, -0.260369, -0.622045], [ 0.887071, -1.535595, -0.415564, ..., -0.018066, 1.114056, -0.139325], ..., [-0.673667, -0.113091, 2.902986, ..., -1.630196, -0.690223, 0.282306], [-0.489038, -0.629943, -0.028659, ..., 0.40166 , -0.325158, -0.894023], [-0.181595, -0.130769, -1.416751, ..., 0.5054 , -0.375838, -0.419939]]) . | diverging(chain, draw)bool...array([[False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], ..., [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False]]) . | tree_size(chain, draw)float64...array([[31., 31., 31., ..., 31., 31., 31.], [31., 31., 31., ..., 31., 31., 31.], [31., 31., 31., ..., 31., 31., 31.], ..., [31., 31., 31., ..., 31., 31., 31.], [31., 31., 31., ..., 31., 31., 31.], [31., 31., 31., ..., 31., 31., 31.]]) . | step_size_bar(chain, draw)float64...array([[0.163001, 0.163001, 0.163001, ..., 0.163001, 0.163001, 0.163001], [0.160479, 0.160479, 0.160479, ..., 0.160479, 0.160479, 0.160479], [0.156359, 0.156359, 0.156359, ..., 0.156359, 0.156359, 0.156359], ..., [0.156953, 0.156953, 0.156953, ..., 0.156953, 0.156953, 0.156953], [0.155184, 0.155184, 0.155184, ..., 0.155184, 0.155184, 0.155184], [0.155511, 0.155511, 0.155511, ..., 0.155511, 0.155511, 0.155511]]) . | . | Attributes: (6)created_at :2021-01-06T18:05:36.497940arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3sampling_time :1202.0958020687103tuning_steps :1000 | . . | observed_data . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (timesteps: 224) Coordinates: * timesteps (timesteps) datetime64[ns] 2002-05-31 2002-06-30 ... 2020-12-31 Data variables: y (timesteps) int32 485 490 505 535 534 524 ... 379 320 373 456 320 Attributes: created_at: 2021-01-06T18:06:00.290101 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 . xarray.DatasetDimensions:timesteps: 224 | . | Coordinates: (1)timesteps(timesteps)datetime64[ns]2002-05-31 ... 2020-12-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2020-10-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-11-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-12-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (1)y(timesteps)int32...array([485, 490, 505, ..., 373, 456, 320], dtype=int32) . | . | Attributes: (4)created_at :2021-01-06T18:06:00.290101arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3 | . . | constant_data . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (timesteps: 224) Coordinates: * timesteps (timesteps) datetime64[ns] 2002-05-31 ... 2020-12-31 Data variables: election_flag (timesteps) int32 1 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 stdz_log_unemployment (timesteps) float64 -1.452 -1.452 ... 0.1465 0.1465 Attributes: created_at: 2021-01-06T18:06:00.291262 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 . xarray.DatasetDimensions:timesteps: 224 | . | Coordinates: (1)timesteps(timesteps)datetime64[ns]2002-05-31 ... 2020-12-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2020-10-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-11-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2020-12-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (2)election_flag(timesteps)int32...array([1, 0, 0, ..., 0, 0, 0], dtype=int32) . | stdz_log_unemployment(timesteps)float64...array([-1.452355, -1.452355, -1.452355, ..., 0.146469, 0.146469, 0.146469]) . | . | Attributes: (4)created_at :2021-01-06T18:06:00.291262arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3 | . . | predictions_constant_data . . . . . . . &lt;xarray.Dataset&gt; Dimensions: (timesteps: 227) Coordinates: * timesteps (timesteps) datetime64[ns] 2002-05-31 ... 2021-03-31 Data variables: election_flag (timesteps) int32 1 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 stdz_log_unemployment (timesteps) float64 -1.452 -1.452 ... 0.08843 Attributes: created_at: 2021-01-12T17:44:53.344671 arviz_version: 0.10.0 inference_library: pymc3 inference_library_version: 3.9.3 . xarray.DatasetDimensions:timesteps: 227 | . | Coordinates: (1)timesteps(timesteps)datetime64[ns]2002-05-31 ... 2021-03-31array([&amp;#x27;2002-05-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-06-30T00:00:00.000000000&amp;#x27;, &amp;#x27;2002-07-31T00:00:00.000000000&amp;#x27;, ..., &amp;#x27;2021-01-31T00:00:00.000000000&amp;#x27;, &amp;#x27;2021-02-28T00:00:00.000000000&amp;#x27;, &amp;#x27;2021-03-31T00:00:00.000000000&amp;#x27;], dtype=&amp;#x27;datetime64[ns]&amp;#x27;) . | . | Data variables: (2)election_flag(timesteps)int321 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32) . | stdz_log_unemployment(timesteps)float64-1.452 -1.452 ... -0.04889 0.08843array([-1.45235546, -1.45235546, -1.45235546, -1.45235546, -1.45235546, -1.31987524, -1.31987524, -1.31987524, -0.80683404, -0.80683404, -0.80683404, -0.68258262, -0.68258262, -0.68258262, -0.80683404, -0.80683404, -0.80683404, -0.31882942, -0.31882942, -0.31882942, -0.08347479, -0.08347479, -0.08347479, -0.31882942, -0.31882942, -0.31882942, -0.20045987, -0.20045987, -0.20045987, -0.20045987, -0.20045987, -0.20045987, -0.43861661, -0.43861661, -0.43861661, -0.31882942, -0.31882942, -0.31882942, -0.08347479, -0.08347479, -0.08347479, 0.03215784, 0.03215784, 0.03215784, 0.14646892, 0.14646892, 0.14646892, -0.08347479, -0.08347479, -0.08347479, -0.20045987, -0.20045987, -0.20045987, -0.80683404, -0.80683404, -0.80683404, -0.68258262, -0.68258262, -0.68258262, -1.06006555, -1.06006555, -1.06006555, -1.31987524, -1.31987524, -1.31987524, -2.0005535 , -2.0005535 , -2.0005535 , -2.43236634, -2.43236634, -2.43236634, -2.14242979, -2.14242979, -2.14242979, -2.0005535 , -2.0005535 , -2.0005535 , -1.586614 , -1.586614 , -1.586614 , -0.5598558 , -0.5598558 , -0.5598558 , 0.14646892, 0.14646892, 0.14646892, 0.14646892, 0.14646892, 0.14646892, 0.48176659, 0.48176659, 0.48176659, 0.3712449 , 0.3712449 , 0.3712449 , 0.25948832, 0.25948832, 0.25948832, 0.14646892, 0.14646892, ... 1.32454786, 1.52459674, 1.52459674, 1.52459674, 1.32454786, 1.32454786, 1.32454786, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.22300272, 1.32454786, 1.32454786, 1.32454786, 1.52459674, 1.52459674, 1.52459674, 1.42507243, 1.42507243, 1.42507243, 1.6231405 , 1.6231405 , 1.6231405 , 1.42507243, 1.42507243, 1.42507243, 1.32454786, 1.32454786, 1.32454786, 1.32454786, 1.32454786, 1.32454786, 1.12041607, 1.12041607, 1.12041607, 1.01676633, 1.01676633, 1.01676633, 1.12041607, 1.12041607, 1.12041607, 0.69921234, 0.69921234, 0.69921234, 0.59108036, 0.59108036, 0.59108036, 0.59108036, 0.59108036, 0.59108036, -0.08347479, -0.08347479, -0.08347479, 0.3712449 , 0.3712449 , 0.3712449 , 0.14646892, 0.14646892, 0.14646892, -0.08347479, -0.08347479, -0.08347479, -0.31882942, -0.31882942, -0.31882942, -0.31882942, -0.31882942, -0.31882942, -0.5598558 , -0.5598558 , -0.5598558 , -0.68258262, -0.68258262, -0.68258262, -1.06006555, -1.06006555, -1.06006555, -1.31987524, -1.31987524, -1.31987524, -2.14242979, -2.14242979, -2.14242979, 0.14646892, 0.14646892, 0.14646892, 0.14646892, 0.14646892, 0.14646892, -0.26766595, -0.04889151, 0.08842622]) . | . | Attributes: (4)created_at :2021-01-12T17:44:53.344671arviz_version :0.10.0inference_library :pymc3inference_library_version :3.9.3 | . . | . pp_prop = logistic( trace_econ.predictions[&quot;baseline&quot;] + trace_econ.predictions[&quot;f_time_new&quot;] + trace_econ.predictions[&quot;honeymoon&quot;] * trace_econ.predictions_constant_data[&quot;election_flag&quot;] + trace_econ.predictions[&quot;log_unemp_effect&quot;] * trace_econ.predictions_constant_data[&quot;stdz_log_unemployment&quot;] ) . pp_prop_10 = logistic( trace_econ.predictions[&quot;baseline&quot;] + trace_econ.predictions[&quot;f_time_new&quot;] + trace_econ.predictions[&quot;honeymoon&quot;] * trace_econ.predictions_constant_data[&quot;election_flag&quot;] + trace_econ.predictions[&quot;log_unemp_effect&quot;] * xr.DataArray( np.concatenate((standardize(log_unemp).values, oos_unemp_10)), dims=[&quot;timesteps&quot;], coords=PREDICTION_COORDS, ) ) . pp_prop_5 = logistic( trace_econ.predictions[&quot;baseline&quot;] + trace_econ.predictions[&quot;f_time_new&quot;] + trace_econ.predictions[&quot;honeymoon&quot;] * trace_econ.predictions_constant_data[&quot;election_flag&quot;] + trace_econ.predictions[&quot;log_unemp_effect&quot;] * xr.DataArray( np.concatenate((standardize(log_unemp).values, oos_unemp_5)), dims=[&quot;timesteps&quot;], coords=PREDICTION_COORDS, ) ) . raw_polls = all_presidents.loc[all_presidents.index &gt;= pd.to_datetime(&quot;2002-05-05&quot;)] # convert to proportions raw_polls[[&quot;approve_pr&quot;, &quot;disapprove_pr&quot;]] = ( raw_polls[[&quot;approve_pr&quot;, &quot;disapprove_pr&quot;]].copy() / 100 ) raw_polls = raw_polls.rename( columns={&quot;approve_pr&quot;: &quot;p_approve&quot;, &quot;disapprove_pr&quot;: &quot;p_disapprove&quot;} ) . /Users/alex_andorra/opt/anaconda3/envs/elections-models/lib/python3.8/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy self[k1] = value[k2] . pandas 1.0.5 pymc3 3.9.3 numpy 1.19.1 xarray 0.16.0 arviz 0.10.0 AlexAndorra last updated: Tue Jan 12 2021 CPython 3.8.5 IPython 7.19.0 .",
            "url": "https://alexandorra.github.io/pollsposition_website/popularity/macron/gaussian%20processes/polls/2021/01/12/gp-popularity.html",
            "relUrl": "/popularity/macron/gaussian%20processes/polls/2021/01/12/gp-popularity.html",
            "date": " • Jan 12, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "The PollsPosition project is an open-source endeavor with three main goals: . Exploring new statistical methods and applying them to real-life issues and datasets. This is a way for me to gain new skills and stay up to date with the field of Bayesian statistics, where the fun part is that you&#39;re never done learning! As such, I like to call PollsPosition my &quot;nerdy sandbox&quot; 🤓 Understanding how and why people make decisions when they don’t have all the facts is fascinating to me. That’s why I like, among others, electoral forecasting, and I use it as a sparring partner. | Popularizing and illustrating the power of Bayesian statistics. These are especially helpful in contexts where data are sparse and imprecise, domain knowledge is important, and estimating uncertainty is one of the main interest of the analysis. Well look at that: democratic elections check all these boxes ✅ Icing on the cake, French political parties are numerous and change in nature -- compared to the US for instance -- which makes the models all the more complicated, but also... interesting! If you&#39;re curious, I presented a talk in 2020 about a version of the model: | A last, broader goal is to try to counteract our natural tendencies (especially during electoral campaigns!) to cherry-pick data, overreact to the latest poll, and, most importantly, completely misinterpret uncertainties and probabilities. I was invited on a podcast in 2020 to talk about just that, if that&#39;s of interest to you 📻 I&#39;m perfectly aware that it&#39;s a lofty and probably unattainable goal. I do believe that spreading the methods of rational and critical thinking is essential though, so I can at least try 🤷‍♂ For sure, I can&#39;t do it alone, so if you like what we do at PollsPosition, feel free to share our content with your friends and colleagues -- or if you don&#39;t like it, share it with people you don&#39;t like, that works too! The Local Maximum · Ep. 140 - Why Polls are Tricky with Alex Andorra | If this all sounds fun to you and you&#39;re looking for a project to improve your Python and Bayesian chops, feel free to contribute pull requests -- there is always something to do! . My name is Alexandre Andorra by the way. By day, I&#39;m a Bayesian modeler at the PyMC Labs consultancy and host the most popular podcast dedicated to Bayesian inference out there -- aka Learning Bayesian Statistics . By night, I don&#39;t (yet) fight crime, but I&#39;m an open-source enthusiast and core contributor to the awesome Python packages PyMC and ArviZ . . An always-learning statistician, I love building models and studying elections and human behavior. I also love Nutella a bit too much, but I don&#39;t like talking about it – I prefer eating it 😋 . I can&#39;t finish without acknowledging the people who help me in this nerdy adventure, most notably the brilliant Alexis Bergès who devises with me for hours about ways to best model elections, as well as the wonderful core-developers of ArviZ and PyMC, who often indulge my unrelenting stats questions 🤩 . Feel free to reach out on Twitter if you want to talk about chocolate, statistical modeling under certainty, or how &quot;polls are useless now because they missed two elections in a row!&quot; -- yeah, I&#39;m a bit sarcastic. .",
          "url": "https://alexandorra.github.io/pollsposition_website/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://alexandorra.github.io/pollsposition_website/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}